{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88351cc5",
   "metadata": {},
   "source": [
    "# ğŸƒ CNN zur Spielkarten-Klassifikation\n",
    "## Ein didaktisches Beispielprojekt fÃ¼r Einsteiger\n",
    "\n",
    "---\n",
    "\n",
    "### Was wirst du in diesem Notebook lernen?\n",
    "\n",
    "Dieses Notebook fÃ¼hrt dich Schritt fÃ¼r Schritt durch die Implementierung eines **Convolutional Neural Networks (CNN)** zur **Bildklassifikation von Spielkarten**. Am Ende wirst du verstehen:\n",
    "\n",
    "1. **Was ist ein Neuronales Netz?** - Die Grundlagen von kÃ¼nstlichen Neuronen, Gewichten und Aktivierungsfunktionen\n",
    "2. **Was ist ein CNN?** - Warum Faltungsnetzwerke besonders gut fÃ¼r Bilder geeignet sind\n",
    "3. **Die CNN-Architektur:** - Convolution Layer, Pooling Layer, Dense Layer und wie sie zusammenarbeiten\n",
    "4. **Training eines CNNs:** - Wie das Netzwerk durch Backpropagation lernt\n",
    "5. **Evaluation:** - Wie wir die Leistung unseres Modells messen\n",
    "\n",
    "---\n",
    "\n",
    "### Theoretischer Hintergrund: Was ist ein Neuronales Netz?\n",
    "\n",
    "Ein **kÃ¼nstliches neuronales Netz** ist ein mathematisches Modell, das sich an der Funktionsweise des menschlichen Gehirns orientiert. Es besteht aus:\n",
    "\n",
    "- **Neuronen (Knoten):** Verarbeitungseinheiten, die Eingaben empfangen und Ausgaben produzieren\n",
    "- **Gewichte (Weights):** Zahlen, die die StÃ¤rke der Verbindung zwischen Neuronen bestimmen\n",
    "- **Aktivierungsfunktionen:** Funktionen, die bestimmen, ob ein Neuron \"feuert\" oder nicht\n",
    "\n",
    "**Wie lernt ein neuronales Netz?**\n",
    "1. **Forward Pass:** Eingabe wird durch das Netzwerk geschickt â†’ Vorhersage entsteht\n",
    "2. **Loss-Berechnung:** Wie weit liegt die Vorhersage vom wahren Wert entfernt?\n",
    "3. **Backpropagation:** Der Fehler wird rÃ¼ckwÃ¤rts durch das Netz propagiert\n",
    "4. **Gewichtsanpassung:** Die Gewichte werden angepasst, um den Fehler zu minimieren\n",
    "\n",
    "---\n",
    "\n",
    "### Was ist ein Convolutional Neural Network (CNN)?\n",
    "\n",
    "Ein **CNN** ist eine spezielle Art von neuronalem Netz, das besonders gut fÃ¼r **Bilddaten** geeignet ist. Der Grund:\n",
    "\n",
    "- **Faltung (Convolution):** Erkennt lokale Muster wie Kanten, Ecken, Texturen\n",
    "- **Translation Invarianz:** Erkennt Objekte unabhÃ¤ngig von ihrer Position im Bild\n",
    "- **Parametereffizient:** Teilt Gewichte, braucht weniger Parameter als voll verbundene Netze\n",
    "\n",
    "**Typischer CNN-Aufbau (wie in der Vorlesung):**\n",
    "\n",
    "```\n",
    "Eingabe â†’ [Convolution â†’ ReLU â†’ Pooling] Ã— n â†’ Flatten â†’ Dense â†’ Softmax â†’ Ausgabe\n",
    "```\n",
    "\n",
    "Wir werden genau diese Architektur implementieren!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed0bdb",
   "metadata": {},
   "source": [
    "## 1. Bibliotheken importieren und Umgebung prÃ¼fen\n",
    "\n",
    "Bevor wir beginnen, mÃ¼ssen wir die notwendigen Bibliotheken importieren. \n",
    "\n",
    "**BenÃ¶tigte Bibliotheken:**\n",
    "- `tensorflow` / `keras`: Das Deep-Learning-Framework zum Erstellen und Trainieren des CNNs\n",
    "- `numpy`: FÃ¼r numerische Berechnungen mit Arrays\n",
    "- `matplotlib`: Zum Visualisieren von Bildern und TrainingsverlÃ¤ufen\n",
    "- `kagglehub`: Zum Herunterladen des Spielkarten-Datensatzes von Kaggle\n",
    "- `scikit-learn`: FÃ¼r Metriken wie die Confusion Matrix\n",
    "\n",
    "**Installation (falls noch nicht geschehen):**\n",
    "```bash\n",
    "pip install tensorflow kagglehub matplotlib scikit-learn numpy pillow\n",
    "```\n",
    "\n",
    "FÃ¼r macOS mit Apple Silicon (M1/M2/M3):\n",
    "```bash\n",
    "pip install tensorflow-macos tensorflow-metal kagglehub matplotlib scikit-learn numpy pillow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. BIBLIOTHEKEN IMPORTIEREN\n",
    "# ==============================================================================\n",
    "# In diesem Abschnitt laden wir alle Python-Bibliotheken, die wir fÃ¼r unser\n",
    "# CNN-Projekt benÃ¶tigen. Jede Bibliothek hat eine spezifische Aufgabe.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Hinweis zur Installation ---\n",
    "# Falls eine der folgenden Bibliotheken nicht installiert ist, fÃ¼hre in der\n",
    "# Konsole folgenden Befehl aus:\n",
    " # pip install tensorflow matplotlib scikit-learn numpy pillow seaborn\n",
    "#\n",
    "# FÃ¼r macOS mit Apple Silicon (M1/M2/M3) verwende stattdessen:\n",
    "# pip install tensorflow-macos tensorflow-metal matplotlib scikit-learn numpy pillow seaborn\n",
    "\n",
    "# --- Standard-Bibliotheken (in Python bereits enthalten) ---\n",
    "import os                  # FÃ¼r Dateisystem-Operationen (Ordner durchsuchen, Pfade bauen)\n",
    "import random              # FÃ¼r zufÃ¤llige Auswahl (z.B. Beispielbilder)\n",
    "import subprocess          # FÃ¼r das AusfÃ¼hren von Shell-Befehlen (curl)\n",
    "import zipfile             # FÃ¼r das Entpacken von ZIP-Archiven\n",
    "import shutil              # FÃ¼r Dateioperationen (kopieren, verschieben)\n",
    "import re                  # Regular Expressions fÃ¼r Textmuster\n",
    "\n",
    "# --- TensorFlow / Keras ---\n",
    "# TensorFlow ist ein Open-Source-Framework fÃ¼r Machine Learning von Google.\n",
    "# Keras ist eine High-Level-API innerhalb von TensorFlow, die das Erstellen\n",
    "# von neuronalen Netzen sehr einfach macht. Wir verwenden Keras, weil es\n",
    "# fÃ¼r Einsteiger besonders gut lesbar und verstÃ¤ndlich ist.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential  # FÃ¼r sequentielle Modelle\n",
    "\n",
    "# --- NumPy ---\n",
    "# NumPy ist DIE Bibliothek fÃ¼r numerische Berechnungen in Python.\n",
    "# Bilder werden intern als NumPy-Arrays (mehrdimensionale Matrizen) dargestellt.\n",
    "import numpy as np\n",
    "\n",
    "# --- Matplotlib ---\n",
    "# Matplotlib ist die Standard-Bibliothek zum Erstellen von Grafiken und Plots.\n",
    "# Wir nutzen sie, um Bilder anzuzeigen und den Trainingsverlauf zu visualisieren.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Scikit-learn (sklearn) ---\n",
    "# Scikit-learn bietet viele nÃ¼tzliche Funktionen fÃ¼r Machine Learning.\n",
    "# Wir nutzen es hier fÃ¼r die Confusion Matrix zur Evaluation.\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns  # FÃ¼r schÃ¶nere Confusion-Matrix-Visualisierung\n",
    "\n",
    "# ==============================================================================\n",
    "# PROJEKTPFADE DEFINIEREN (RELATIVE PFADE!)\n",
    "# ==============================================================================\n",
    "# Wir verwenden relative Pfade, damit das Projekt auf jedem System lÃ¤uft.\n",
    "# Alle Daten werden im ./data/ Ordner gespeichert.\n",
    "# ==============================================================================\n",
    "\n",
    "DATA_DIR = \"./data\"                                          # Hauptordner fÃ¼r alle Daten\n",
    "DATASET_ZIP = os.path.join(DATA_DIR, \"playing-cards.zip\")    # ZIP-Datei\n",
    "DATASET_DIR = os.path.join(DATA_DIR, \"playing-cards\")        # Entpackter Datensatz\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Alle Bibliotheken erfolgreich importiert!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nğŸ“ Projektpfade (relativ):\")\n",
    "print(f\"   Daten-Ordner:    {DATA_DIR}\")\n",
    "print(f\"   ZIP-Datei:       {DATASET_ZIP}\")\n",
    "print(f\"   Dataset-Ordner:  {DATASET_DIR}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1.1 UMGEBUNG PRÃœFEN: TensorFlow-Version und GPU-VerfÃ¼gbarkeit\n",
    "# ==============================================================================\n",
    "# Bevor wir beginnen, prÃ¼fen wir unsere Umgebung:\n",
    "# - Welche TensorFlow-Version ist installiert?\n",
    "# - Ist eine GPU verfÃ¼gbar? (GPUs beschleunigen das Training erheblich)\n",
    "#\n",
    "# Was ist eine GPU?\n",
    "# Eine GPU (Graphics Processing Unit) ist ein Prozessor, der ursprÃ¼nglich fÃ¼r\n",
    "# Grafikberechnungen entwickelt wurde. Da Deep Learning viele parallele Matrix-\n",
    "# operationen erfordert, sind GPUs dafÃ¼r ideal. Training auf GPU kann 10-100x\n",
    "# schneller sein als auf CPU!\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"UMGEBUNGS-CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TensorFlow-Version anzeigen\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# PrÃ¼fen, ob GPUs verfÃ¼gbar sind\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"âœ… GPU gefunden: {len(gpus)} GPU(s) verfÃ¼gbar\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"   - {gpu}\")\n",
    "    print(\"   Das Training wird auf der GPU ausgefÃ¼hrt (schneller!)\")\n",
    "else:\n",
    "    print(\"âš ï¸ Keine GPU gefunden - Training lÃ¤uft auf CPU\")\n",
    "    print(\"   Das ist vÃ¶llig okay, dauert nur etwas lÃ¤nger.\")\n",
    "\n",
    "# Keras-Backend anzeigen\n",
    "print(f\"Keras Backend: {keras.backend.backend()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc89809",
   "metadata": {},
   "source": [
    "## 2. Datensatz von Kaggle herunterladen\n",
    "\n",
    "Wir verwenden den **\"Complete Playing Card Dataset\"** von Kaggle. Dieser Datensatz enthÃ¤lt Bilder von 53 verschiedenen Spielkarten (52 Standard-Karten + Joker).\n",
    "\n",
    "**Was ist Kaggle?**\n",
    "Kaggle ist eine Plattform fÃ¼r Data Science und Machine Learning. Dort findest du:\n",
    "- Tausende von DatensÃ¤tzen (kostenlos!)\n",
    "- Wettbewerbe mit Preisgeldern\n",
    "- Notebooks und Tutorials\n",
    "\n",
    "**Ãœber den Datensatz:**\n",
    "- **Anzahl Klassen:** 53 (z.B. \"ace_of_spades\", \"king_of_hearts\", \"joker\")\n",
    "- **Bilder pro Klasse:** ca. 50-100 Bilder\n",
    "- **Format:** JPG/PNG Bilder in Unterordnern nach Kartentyp sortiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a196be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. DATENSATZ MIT CURL HERUNTERLADEN\n",
    "# ==============================================================================\n",
    "# Wir laden den Spielkarten-Datensatz direkt von Kaggle mit curl herunter.\n",
    "# Das funktioniert ohne zusÃ¤tzliche AbhÃ¤ngigkeiten und speichert die Daten\n",
    "# im ./data/ Ordner - so bleibt alles im Projekt zusammen!\n",
    "#\n",
    "# VORTEILE:\n",
    "# - Keine Kaggle-Credentials erforderlich (Ã¶ffentlicher Download)\n",
    "# - Relative Pfade = funktioniert auf jedem System\n",
    "# - Daten im Projekt = einfach zu verwalten\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATENSATZ HERUNTERLADEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- Ordner erstellen falls nicht vorhanden ---\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# --- PrÃ¼fen ob Daten schon vorhanden ---\n",
    "bilder_pfad = os.path.join(DATASET_DIR, \"Images\", \"Images\")\n",
    "if os.path.exists(bilder_pfad) and os.listdir(bilder_pfad):\n",
    "    print(f\"âœ… Datensatz bereits vorhanden in: {DATASET_DIR}\")\n",
    "    print(f\"   Bilder gefunden: {len(os.listdir(bilder_pfad))}\")\n",
    "    print(\"   Ãœberspringe Download...\")\n",
    "else:\n",
    "    # --- ZIP herunterladen falls nicht vorhanden ---\n",
    "    if not os.path.exists(DATASET_ZIP):\n",
    "        print(\"ğŸ“¥ Lade Datensatz von Kaggle herunter...\")\n",
    "        print(\"   (Das kann einige Minuten dauern)\\n\")\n",
    "        \n",
    "        # curl-Befehl ausfÃ¼hren\n",
    "        curl_command = [\n",
    "            \"curl\", \"-L\", \"--progress-bar\",\n",
    "            \"-o\", DATASET_ZIP,\n",
    "            \"https://www.kaggle.com/api/v1/datasets/download/jaypradipshah/the-complete-playing-card-dataset\"\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(curl_command)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(\"Download fehlgeschlagen! PrÃ¼fe deine Internetverbindung.\")\n",
    "        \n",
    "        print(f\"\\nâœ… Download abgeschlossen: {DATASET_ZIP}\")\n",
    "    else:\n",
    "        print(f\"âœ… ZIP-Datei bereits vorhanden: {DATASET_ZIP}\")\n",
    "    \n",
    "    # --- ZIP entpacken ---\n",
    "    print(f\"\\nğŸ“¦ Entpacke ZIP-Datei nach {DATASET_DIR}...\")\n",
    "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATASET_DIR)\n",
    "    \n",
    "    print(\"âœ… Entpacken abgeschlossen!\")\n",
    "\n",
    "print(f\"\\nğŸ“ Datensatz-Pfad: {DATASET_DIR}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c45cb",
   "metadata": {},
   "source": [
    "## 3. Datensatz erkunden: Ordnerstruktur verstehen\n",
    "\n",
    "Bevor wir mit dem Training beginnen, sollten wir verstehen, wie der Datensatz organisiert ist.\n",
    "\n",
    "### Die Struktur dieses Datensatzes\n",
    "\n",
    "```\n",
    "the-complete-playing-card-dataset/\n",
    "â”‚\n",
    "â”œâ”€â”€ ğŸ“ Images/Images/        â† ğŸ–¼ï¸ HIER SIND UNSERE BILDER!\n",
    "â”‚       â”œâ”€â”€ 10C0.jpg             Alle ~2650 Bilder in EINEM Ordner\n",
    "â”‚       â”œâ”€â”€ AC0.jpg              Dateiname = Klasse + Bildnummer\n",
    "â”‚       â””â”€â”€ ...\n",
    "â”‚\n",
    "â”œâ”€â”€ ğŸ“ Annotations/          â† âŒ Pascal VOC Format (ignorieren wir)\n",
    "â”œâ”€â”€ ğŸ“ YOLO_Annotations/     â† âŒ YOLO Format (ignorieren wir)\n",
    "â””â”€â”€ ğŸ“„ annotation.json       â† âŒ COCO Format (ignorieren wir)\n",
    "```\n",
    "\n",
    "**Hinweis zu den Annotations-Ordnern:**\n",
    "Dieser Datensatz wurde fÃ¼r **Object Detection** erstellt (Karten in Bildern lokalisieren).\n",
    "Die Annotations enthalten Bounding Boxes - wir brauchen sie **nicht** fÃ¼r Klassifikation!\n",
    "\n",
    "### Wir machen KLASSIFIKATION:\n",
    "- **Object Detection:** \"Wo ist die Karte?\" â†’ Braucht Bounding Boxes\n",
    "- **Klassifikation:** \"Welche Karte ist das?\" â†’ Braucht nur Labels (aus Dateinamen)\n",
    "\n",
    "### Dateinamen-Schema\n",
    "\n",
    "| Dateiname | Klasse | Bedeutung |\n",
    "|-----------|--------|-----------|\n",
    "| `10C0.jpg` | `10C` | 10 of Clubs (Kreuz-10) |\n",
    "| `AC5.jpg` | `AC` | Ace of Clubs (Kreuz-Ass) |\n",
    "| `KH12.jpg` | `KH` | King of Hearts (Herz-KÃ¶nig) |\n",
    "| `JOKER3.jpg` | `JOKER` | Joker |\n",
    "\n",
    "**KÃ¼rzel:** `A`=Ass, `J`=Bube, `Q`=Dame, `K`=KÃ¶nig | `C`=Kreuzâ™£, `D`=Karoâ™¦, `H`=Herzâ™¥, `S`=Pikâ™ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. DATENSATZ ERKUNDEN: ORDNERSTRUKTUR ANALYSIEREN\n",
    "# ==============================================================================\n",
    "# Wir schauen uns an, wie der Datensatz aufgebaut ist.\n",
    "# Dies hilft uns zu verstehen:\n",
    "# - Wo liegen die Bilder?\n",
    "# - Wie sind die Klassen (Kartentypen) organisiert?\n",
    "# - Wie viele Bilder haben wir insgesamt?\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATENSATZ-STRUKTUR ERKUNDEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- Schritt 1: Hauptordner anzeigen ---\n",
    "print(\"\\nğŸ“‚ Inhalt des Hauptordners:\")\n",
    "hauptordner_inhalt = os.listdir(DATASET_DIR)\n",
    "for item in sorted(hauptordner_inhalt):\n",
    "    item_pfad = os.path.join(DATASET_DIR, item)\n",
    "    if os.path.isdir(item_pfad):\n",
    "        print(f\"   ğŸ“ {item}/\")\n",
    "    else:\n",
    "        print(f\"   ğŸ“„ {item}\")\n",
    "\n",
    "# --- Schritt 2: Den Bilder-Ordner finden ---\n",
    "# Bei diesem Datensatz liegen die Bilder in: Images/Images/\n",
    "bilder_ordner = os.path.join(DATASET_DIR, \"Images\", \"Images\")\n",
    "\n",
    "if os.path.exists(bilder_ordner):\n",
    "    print(f\"\\nâœ… Bilder-Ordner gefunden: {bilder_ordner}\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Bilder-Ordner nicht gefunden!\")\n",
    "    print(\"   Erwarteter Pfad:\", bilder_ordner)\n",
    "\n",
    "# --- Schritt 3: Bilder und Dateinamen analysieren ---\n",
    "alle_bilder = [f for f in os.listdir(bilder_ordner) \n",
    "               if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "print(f\"\\nğŸ“¸ Anzahl der Bilder im Ordner: {len(alle_bilder)}\")\n",
    "\n",
    "# Erste 10 Dateinamen anzeigen\n",
    "print(f\"\\nğŸ“‹ Beispiel-Dateinamen (erste 10):\")\n",
    "for datei in sorted(alle_bilder)[:10]:\n",
    "    print(f\"   {datei}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3.1 KLASSEN AUS DATEINAMEN EXTRAHIEREN\n",
    "# ==============================================================================\n",
    "# Da die Bilder nicht in Unterordnern liegen, mÃ¼ssen wir die Klasse\n",
    "# aus dem Dateinamen ableiten.\n",
    "#\n",
    "# Dateinamen-Schema: <Klasse><Bildnummer>.jpg\n",
    "# Beispiele: \"10C0.jpg\" â†’ Klasse \"10C\", \"AC5.jpg\" â†’ Klasse \"AC\"\n",
    "#\n",
    "# Wir brauchen eine Funktion, die den Klassennamen aus dem Dateinamen extrahiert.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"KLASSEN AUS DATEINAMEN EXTRAHIEREN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# re (Regular Expressions) wurde bereits oben importiert\n",
    "\n",
    "def extrahiere_klasse(dateiname):\n",
    "    \"\"\"\n",
    "    Extrahiert den Klassennamen aus einem Dateinamen.\n",
    "    \n",
    "    Beispiele:\n",
    "    - \"10C0.jpg\" â†’ \"10C\" (10 of Clubs)\n",
    "    - \"AC5.jpg\" â†’ \"AC\" (Ace of Clubs)\n",
    "    - \"KH12.jpg\" â†’ \"KH\" (King of Hearts)\n",
    "    - \"JOKER3.jpg\" â†’ \"JOKER\"\n",
    "    \n",
    "    Die Logik:\n",
    "    - Entferne die Dateiendung (.jpg)\n",
    "    - Entferne die Bildnummer am Ende (Ziffern)\n",
    "    - Was Ã¼brig bleibt, ist die Klasse\n",
    "    \"\"\"\n",
    "    # Dateiendung entfernen\n",
    "    name_ohne_endung = os.path.splitext(dateiname)[0]\n",
    "    \n",
    "    # Ziffern am Ende entfernen (das ist die Bildnummer)\n",
    "    # \\d+$ bedeutet: Eine oder mehr Ziffern am Ende des Strings\n",
    "    klasse = re.sub(r'\\d+$', '', name_ohne_endung)\n",
    "    \n",
    "    return klasse\n",
    "\n",
    "# --- Alle Klassen sammeln ---\n",
    "klassen_set = set()  # Set = Menge ohne Duplikate\n",
    "\n",
    "for datei in alle_bilder:\n",
    "    klasse = extrahiere_klasse(datei)\n",
    "    klassen_set.add(klasse)\n",
    "\n",
    "# In sortierte Liste umwandeln\n",
    "klassen = sorted(list(klassen_set))\n",
    "\n",
    "print(f\"\\nğŸ“Š Anzahl der Klassen (Kartentypen): {len(klassen)}\")\n",
    "print(f\"\\nğŸ“‹ Alle {len(klassen)} Klassen:\")\n",
    "\n",
    "# Klassen schÃ¶n formatiert ausgeben (5 pro Zeile)\n",
    "for i in range(0, len(klassen), 5):\n",
    "    zeile = klassen[i:i+5]\n",
    "    print(f\"   {', '.join(zeile)}\")\n",
    "\n",
    "# --- Bilder pro Klasse zÃ¤hlen ---\n",
    "print(f\"\\nğŸ“Š Bilder pro Klasse:\")\n",
    "bilder_pro_klasse = {}\n",
    "for datei in alle_bilder:\n",
    "    klasse = extrahiere_klasse(datei)\n",
    "    bilder_pro_klasse[klasse] = bilder_pro_klasse.get(klasse, 0) + 1\n",
    "\n",
    "# Anzeigen (sortiert nach Klassenname)\n",
    "for klasse in sorted(bilder_pro_klasse.keys()):\n",
    "    anzahl = bilder_pro_klasse[klasse]\n",
    "    print(f\"   {klasse:8}: {anzahl:3} Bilder\")\n",
    "\n",
    "print(f\"\\nğŸ“¸ Gesamtzahl aller Bilder: {len(alle_bilder)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3.2 BEISPIELBILDER ANZEIGEN\n",
    "# ==============================================================================\n",
    "# Es ist immer eine gute Idee, sich die Daten anzuschauen, bevor man ein\n",
    "# Modell trainiert. So kÃ¶nnen wir:\n",
    "# - Die QualitÃ¤t der Bilder prÃ¼fen\n",
    "# - Verstehen, was das Modell lernen soll\n",
    "# - Eventuelle Probleme im Datensatz erkennen\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BEISPIELBILDER ANZEIGEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Klassennamen in lesbare Namen umwandeln\n",
    "def klasse_zu_name(klasse):\n",
    "    \"\"\"\n",
    "    Wandelt den Klassencode in einen lesbaren Namen um.\n",
    "    \n",
    "    Beispiele:\n",
    "    - \"AC\" â†’ \"Ace of Clubs\"\n",
    "    - \"KH\" â†’ \"King of Hearts\"\n",
    "    - \"10S\" â†’ \"10 of Spades\"\n",
    "    - \"JOKER\" â†’ \"Joker\"\n",
    "    \"\"\"\n",
    "    if klasse == \"JOKER\":\n",
    "        return \"Joker\"\n",
    "    \n",
    "    # Farben-Mapping\n",
    "    farben = {\n",
    "        'C': 'Clubs (Kreuz)',\n",
    "        'D': 'Diamonds (Karo)',\n",
    "        'H': 'Hearts (Herz)',\n",
    "        'S': 'Spades (Pik)'\n",
    "    }\n",
    "    \n",
    "    # Werte-Mapping\n",
    "    werte = {\n",
    "        'A': 'Ace',\n",
    "        'J': 'Jack',\n",
    "        'Q': 'Queen',\n",
    "        'K': 'King'\n",
    "    }\n",
    "    \n",
    "    # Letztes Zeichen ist die Farbe\n",
    "    farbe = klasse[-1]\n",
    "    wert = klasse[:-1]\n",
    "    \n",
    "    # Wert umwandeln (A, J, Q, K oder Zahl)\n",
    "    wert_name = werte.get(wert, wert)\n",
    "    farbe_name = farben.get(farbe, farbe)\n",
    "    \n",
    "    return f\"{wert_name} of {farbe_name}\"\n",
    "\n",
    "# Wir wÃ¤hlen 9 zufÃ¤llige Klassen aus und zeigen je ein Bild\n",
    "anzahl_beispiele = 9\n",
    "zufalls_klassen = random.sample(klassen, min(anzahl_beispiele, len(klassen)))\n",
    "\n",
    "# Plot erstellen: 3x3 Raster von Bildern\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "fig.suptitle(\"Beispielbilder aus dem Spielkarten-Datensatz\", fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (ax, klasse) in enumerate(zip(axes.flat, zufalls_klassen)):\n",
    "    # Ein zufÃ¤lliges Bild dieser Klasse finden\n",
    "    bilder_dieser_klasse = [f for f in alle_bilder if extrahiere_klasse(f) == klasse]\n",
    "    \n",
    "    if bilder_dieser_klasse:\n",
    "        zufalls_bild = random.choice(bilder_dieser_klasse)\n",
    "        bild_pfad = os.path.join(bilder_ordner, zufalls_bild)\n",
    "        \n",
    "        # Bild laden und anzeigen\n",
    "        bild = plt.imread(bild_pfad)\n",
    "        ax.imshow(bild)\n",
    "        \n",
    "        # Lesbaren Namen als Titel\n",
    "        titel = klasse_zu_name(klasse)\n",
    "        ax.set_title(f\"{titel}\\n({klasse})\", fontsize=10)\n",
    "    \n",
    "    ax.axis('off')  # Achsen ausblenden\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ Die Bilder zeigen verschiedene Spielkarten.\")\n",
    "print(\"   Unser CNN soll lernen, diese automatisch zu erkennen!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224abcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3.3 DATEN FÃœR KERAS VORBEREITEN: ORDNERSTRUKTUR ERSTELLEN\n",
    "# ==============================================================================\n",
    "# Keras' image_dataset_from_directory erwartet folgende Struktur:\n",
    "#\n",
    "# daten_ordner/\n",
    "# â”œâ”€â”€ klasse_1/\n",
    "# â”‚   â”œâ”€â”€ bild1.jpg\n",
    "# â”‚   â””â”€â”€ bild2.jpg\n",
    "# â”œâ”€â”€ klasse_2/\n",
    "# â”‚   â”œâ”€â”€ bild1.jpg\n",
    "# â”‚   â””â”€â”€ bild2.jpg\n",
    "# â””â”€â”€ ...\n",
    "#\n",
    "# Unser Datensatz hat aber alle Bilder in einem Ordner!\n",
    "# LÃ¶sung: Wir kopieren die Bilder in eine neue Struktur im ./data/ Ordner.\n",
    "#\n",
    "# WICHTIG: Das machen wir nur einmal! Beim zweiten AusfÃ¼hren wird\n",
    "# erkannt, dass die Ordner schon existieren.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATEN FÃœR KERAS VORBEREITEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- Zielordner definieren (im ./data/ Ordner!) ---\n",
    "# Wir erstellen einen neuen Ordner mit der richtigen Struktur\n",
    "organisierter_ordner = os.path.join(DATA_DIR, \"organized_images\")\n",
    "\n",
    "# PrÃ¼fen, ob die Struktur schon existiert\n",
    "if os.path.exists(organisierter_ordner) and len(os.listdir(organisierter_ordner)) > 0:\n",
    "    print(f\"âœ… Organisierte Ordnerstruktur existiert bereits!\")\n",
    "    print(f\"   Pfad: {organisierter_ordner}\")\n",
    "    print(f\"   Anzahl Klassenordner: {len(os.listdir(organisierter_ordner))}\")\n",
    "    print(\"\\n   Ãœberspringe Kopiervorgang...\")\n",
    "else:\n",
    "    print(f\"ğŸ“ Erstelle organisierte Ordnerstruktur...\")\n",
    "    print(f\"   Ziel: {organisierter_ordner}\")\n",
    "    \n",
    "    # Hauptordner erstellen\n",
    "    os.makedirs(organisierter_ordner, exist_ok=True)\n",
    "    \n",
    "    # FÃ¼r jede Klasse einen Unterordner erstellen und Bilder kopieren\n",
    "    print(f\"\\n   Kopiere Bilder in {len(klassen)} Klassenordner...\")\n",
    "    \n",
    "    for i, klasse in enumerate(klassen):\n",
    "        # Klassenordner erstellen\n",
    "        klassen_ordner = os.path.join(organisierter_ordner, klasse)\n",
    "        os.makedirs(klassen_ordner, exist_ok=True)\n",
    "        \n",
    "        # Alle Bilder dieser Klasse finden und kopieren\n",
    "        bilder_dieser_klasse = [f for f in alle_bilder if extrahiere_klasse(f) == klasse]\n",
    "        \n",
    "        for bild in bilder_dieser_klasse:\n",
    "            quelle = os.path.join(bilder_ordner, bild)\n",
    "            ziel = os.path.join(klassen_ordner, bild)\n",
    "            shutil.copy2(quelle, ziel)\n",
    "        \n",
    "        # Fortschritt anzeigen (alle 10 Klassen)\n",
    "        if (i + 1) % 10 == 0 or (i + 1) == len(klassen):\n",
    "            print(f\"   ... {i + 1}/{len(klassen)} Klassen verarbeitet\")\n",
    "    \n",
    "    print(f\"\\nâœ… Ordnerstruktur erfolgreich erstellt!\")\n",
    "\n",
    "# --- Verifizieren ---\n",
    "print(f\"\\nğŸ“Š ÃœberprÃ¼fung der neuen Struktur:\")\n",
    "for klasse in sorted(os.listdir(organisierter_ordner))[:5]:\n",
    "    klassen_pfad = os.path.join(organisierter_ordner, klasse)\n",
    "    anzahl = len(os.listdir(klassen_pfad))\n",
    "    print(f\"   ğŸ“ {klasse}/: {anzahl} Bilder\")\n",
    "print(f\"   ... ({len(os.listdir(organisierter_ordner))} Ordner insgesamt)\")\n",
    "\n",
    "# Den Pfad fÃ¼r spÃ¤ter speichern\n",
    "bilder_ordner_fuer_training = organisierter_ordner\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e42f5",
   "metadata": {},
   "source": [
    "## 4. Datenvorverarbeitung (Preprocessing)\n",
    "\n",
    "Bevor wir die Bilder in unser CNN geben kÃ¶nnen, mÃ¼ssen wir sie **vorverarbeiten**. Dieser Schritt ist essentiell fÃ¼r erfolgreiches Deep Learning!\n",
    "\n",
    "### Warum Vorverarbeitung?\n",
    "\n",
    "1. **Einheitliche BildgrÃ¶ÃŸe (Resize)**\n",
    "   - Bilder kÃ¶nnen unterschiedliche GrÃ¶ÃŸen haben (z.B. 800x600, 1024x768, ...)\n",
    "   - Neuronale Netze erwarten aber eine **feste EingabegrÃ¶ÃŸe**\n",
    "   - Wir skalieren alle Bilder auf **128 x 128 Pixel**\n",
    "   - Kleinere Bilder = schnelleres Training (fÃ¼r AnfÃ¤nger ideal)\n",
    "\n",
    "2. **Normalisierung der Pixelwerte**\n",
    "   - Pixelwerte liegen normalerweise zwischen 0 und 255 (8-bit RGB)\n",
    "   - Neuronale Netze arbeiten besser mit Werten zwischen **0 und 1**\n",
    "   - Wir teilen jeden Pixelwert durch 255\n",
    "   - Dies hilft dem Gradientenabstieg bei der Optimierung\n",
    "\n",
    "3. **Train/Validation-Split (Aufteilung der Daten)**\n",
    "   - Wir teilen die Daten in **Trainings-** und **Validierungsdaten**\n",
    "   - **Trainingsdaten (80%):** Damit lernt das Modell\n",
    "   - **Validierungsdaten (20%):** Damit prÃ¼fen wir, ob das Modell generalisiert\n",
    "   - Wichtig: Das Modell sieht die Validierungsdaten **nie** wÃ¤hrend des Trainings!\n",
    "\n",
    "### Was ist Overfitting?\n",
    "Wenn ein Modell die Trainingsdaten \"auswendig lernt\" statt zu generalisieren, spricht man von **Overfitting**. Das erkennt man daran, dass die Trainings-Accuracy hoch ist, aber die Validierungs-Accuracy niedrig. Die Aufteilung in Train/Validation hilft uns, dies zu erkennen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec78672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4. HYPERPARAMETER FESTLEGEN\n",
    "# ==============================================================================\n",
    "# Hyperparameter sind Einstellungen, die wir VOR dem Training festlegen.\n",
    "# Sie beeinflussen, wie das Modell trainiert wird.\n",
    "# Im Gegensatz zu den \"normalen\" Parametern (Gewichten) werden Hyperparameter\n",
    "# nicht durch das Training gelernt, sondern von uns gewÃ¤hlt.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"HYPERPARAMETER FESTLEGEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- BildgrÃ¶ÃŸe ---\n",
    "# Alle Bilder werden auf diese GrÃ¶ÃŸe skaliert.\n",
    "#\n",
    "# BILDGRÃ–SSE: 128x128\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Wir verwenden 128x128 Pixel als Kompromiss zwischen Geschwindigkeit und \n",
    "# Genauigkeit. Diese GrÃ¶ÃŸe ermÃ¶glicht schnelleres Training bei akzeptabler\n",
    "# Detailerkennung fÃ¼r Spielkarten.\n",
    "#\n",
    "# | AuflÃ¶sung | Pixelanzahl | Details           | Trainingszeit |\n",
    "# |-----------|-------------|-------------------|---------------|\n",
    "# | 64x64     | 4.096       | Sehr verpixelt    | ~30 Sek       |\n",
    "# | 128x128   | 16.384      | Gut erkennbar âœ“   | ~1 Min        |\n",
    "# | 256x256   | 65.536      | Sehr detailliert  | ~5 Min        |\n",
    "# | 512x512   | 262.144     | Sehr detailliert  | ~20 Min       |\n",
    "#\n",
    "# 128x128 bietet schnelles Training mit guter Genauigkeit!\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# --- Batch Size ---\n",
    "# Wie viele Bilder werden gleichzeitig durch das Netz geschickt?\n",
    "# - GrÃ¶ÃŸere Batches: Stabilere Gradienten, aber mehr Speicher\n",
    "# - Kleinere Batches: Weniger Speicher, aber \"verrauschtere\" Gradienten\n",
    "#\n",
    "# Bei 128x128 Bildern kÃ¶nnen wir eine grÃ¶ÃŸere Batch Size verwenden,\n",
    "# da jedes Bild weniger Speicher benÃ¶tigt.\n",
    "# 128*128*3 = 49.152 Bytes pro Bild\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# --- Epochen ---\n",
    "# Eine Epoche = Das Modell hat ALLE Trainingsbilder einmal gesehen\n",
    "# Mehr Epochen = Mehr Lernzeit, aber Risiko von Overfitting\n",
    "# Wir starten mit 10 Epochen (fÃ¼r schnelle Experimente)\n",
    "EPOCHS = 10\n",
    "\n",
    "# --- Validation Split ---\n",
    "# Welcher Anteil der Daten wird fÃ¼r die Validierung verwendet?\n",
    "# 0.2 = 20% fÃ¼r Validierung, 80% fÃ¼r Training\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# --- Seed fÃ¼r Reproduzierbarkeit ---\n",
    "# Mit einem festen Seed bekommen wir immer die gleichen zufÃ¤lligen Ergebnisse\n",
    "# Das ist wichtig fÃ¼r die Reproduzierbarkeit von Experimenten\n",
    "SEED = 42\n",
    "\n",
    "print(f\"ğŸ“ BildgrÃ¶ÃŸe: {IMG_HEIGHT} x {IMG_WIDTH} Pixel\")\n",
    "print(f\"ğŸ“¦ Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"ğŸ”„ Anzahl Epochen: {EPOCHS}\")\n",
    "print(f\"ğŸ“Š Validation Split: {VALIDATION_SPLIT*100:.0f}%\")\n",
    "print(f\"ğŸ² Random Seed: {SEED}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7123002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4.1 DATENSÃ„TZE LADEN MIT image_dataset_from_directory\n",
    "# ==============================================================================\n",
    "# Keras bietet eine sehr praktische Funktion zum Laden von BilddatensÃ¤tzen:\n",
    "# tf.keras.utils.image_dataset_from_directory\n",
    "#\n",
    "# Diese Funktion:\n",
    "# âœ… LÃ¤dt Bilder automatisch aus Ordnern\n",
    "# âœ… Erstellt Labels automatisch aus Ordnernamen\n",
    "# âœ… Skaliert Bilder auf einheitliche GrÃ¶ÃŸe\n",
    "# âœ… Kann automatisch Train/Validation aufteilen\n",
    "# âœ… Erstellt effiziente tf.data.Dataset-Objekte\n",
    "#\n",
    "# WICHTIG: Wir verwenden hier den organisierten Ordner (bilder_ordner_fuer_training),\n",
    "# den wir in Schritt 3.3 erstellt haben. Dieser hat die richtige Struktur\n",
    "# mit einem Unterordner pro Klasse.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATENSÃ„TZE LADEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"ğŸ“ Lade Bilder aus: {bilder_ordner_fuer_training}\")\n",
    "\n",
    "# --- Trainingsdatensatz laden ---\n",
    "# subset=\"training\" lÃ¤dt 80% der Daten (wegen validation_split=0.2)\n",
    "print(\"\\nğŸ“¥ Lade Trainingsdaten...\")\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    bilder_ordner_fuer_training,      # Pfad zum organisierten Ordner mit Klassenordnern\n",
    "    validation_split=VALIDATION_SPLIT, # 20% fÃ¼r Validierung reservieren\n",
    "    subset=\"training\",                 # Diesen Datensatz als Training verwenden\n",
    "    seed=SEED,                         # Reproduzierbare Aufteilung\n",
    "    image_size=IMG_SIZE,               # Alle Bilder auf 128x128 skalieren\n",
    "    batch_size=BATCH_SIZE,             # 32 Bilder pro Batch\n",
    "    label_mode='int'                   # Labels als Integer (0, 1, 2, ...)\n",
    ")\n",
    "\n",
    "# --- Validierungsdatensatz laden ---\n",
    "# subset=\"validation\" lÃ¤dt die restlichen 20%\n",
    "print(\"\\nğŸ“¥ Lade Validierungsdaten...\")\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    bilder_ordner_fuer_training,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,                         # GLEICHER Seed wie oben! Wichtig!\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "# --- Klassennamen speichern ---\n",
    "# Die Klassennamen werden automatisch aus den Ordnernamen abgeleitet\n",
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"\\nâœ… DatensÃ¤tze erfolgreich geladen!\")\n",
    "print(f\"ğŸ“Š Anzahl der Klassen: {num_classes}\")\n",
    "print(f\"ğŸ“‹ Klassennamen (erste 10): {class_names[:10]}...\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4.2 DATENFORM VERSTEHEN UND PRÃœFEN\n",
    "# ==============================================================================\n",
    "# Bevor wir weitermachen, prÃ¼fen wir die Form unserer Daten.\n",
    "# Dies ist ein wichtiger Debugging-Schritt!\n",
    "#\n",
    "# Bei Bilddaten in TensorFlow/Keras:\n",
    "# - Shape: (Batch, HÃ¶he, Breite, KanÃ¤le)\n",
    "# - Beispiel: (32, 128, 128, 3) bedeutet:\n",
    "#   - 32 Bilder im Batch\n",
    "#   - 128 x 128 Pixel\n",
    "#   - 3 FarbkanÃ¤le (RGB = Rot, GrÃ¼n, Blau)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATENFORM PRÃœFEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Einen Batch aus dem Trainingsdatensatz holen\n",
    "for images_batch, labels_batch in train_dataset.take(1):\n",
    "    print(f\"\\nğŸ“Š Form eines Batches von Bildern: {images_batch.shape}\")\n",
    "    print(f\"   â†’ {images_batch.shape[0]} Bilder\")\n",
    "    print(f\"   â†’ {images_batch.shape[1]} x {images_batch.shape[2]} Pixel\")\n",
    "    print(f\"   â†’ {images_batch.shape[3]} FarbkanÃ¤le (RGB)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Form eines Batches von Labels: {labels_batch.shape}\")\n",
    "    print(f\"   â†’ {labels_batch.shape[0]} Labels (eines pro Bild)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Wertebereich der Pixel: {images_batch.numpy().min():.1f} bis {images_batch.numpy().max():.1f}\")\n",
    "    print(f\"   (Noch nicht normalisiert - wir machen das im Modell!)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Beispiel-Labels: {labels_batch[:5].numpy()}\")\n",
    "    print(f\"   (Diese Zahlen entsprechen den Klassenindizes)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4.3 PERFORMANCE-OPTIMIERUNG (OPTIONAL ABER EMPFOHLEN)\n",
    "# ==============================================================================\n",
    "# TensorFlow bietet einige Techniken, um das Laden der Daten zu beschleunigen:\n",
    "#\n",
    "# 1. cache(): Speichert die Daten im RAM nach dem ersten Durchlauf\n",
    "# 2. prefetch(): LÃ¤dt den nÃ¤chsten Batch, wÃ¤hrend das Modell noch trainiert\n",
    "#\n",
    "# Diese Optimierungen sind besonders bei groÃŸen DatensÃ¤tzen wichtig.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PERFORMANCE-OPTIMIERUNG\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# AUTOTUNE lÃ¤sst TensorFlow die optimale Anzahl automatisch bestimmen\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Trainings- und ValidierungsdatensÃ¤tze optimieren\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"âœ… DatensÃ¤tze fÃ¼r Performance optimiert (cache + prefetch)\")\n",
    "print(\"   â†’ Das Training wird dadurch schneller!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ccab7",
   "metadata": {},
   "source": [
    "## 5. Das CNN-Modell aufbauen\n",
    "\n",
    "Jetzt kommt der spannende Teil: Wir bauen unser **Convolutional Neural Network (CNN)**!\n",
    "\n",
    "### Die Architektur im Ãœberblick\n",
    "\n",
    "Unser CNN folgt dem klassischen Aufbau aus der Vorlesung:\n",
    "\n",
    "```\n",
    "Eingabe (256x256x3)                  â† HÃ¶here AuflÃ¶sung fÃ¼r mehr Details!\n",
    "    â†“\n",
    "[Conv2D â†’ ReLU â†’ MaxPooling] Ã— 4    â† Feature Extraction (4 BlÃ¶cke statt 3!)\n",
    "    â†“\n",
    "Flatten                              â† Umwandlung in 1D-Vektor\n",
    "    â†“\n",
    "Dense (256, ReLU)                    â† Klassifikator (mehr Neuronen)\n",
    "    â†“\n",
    "Dense (num_classes, Softmax)         â† Ausgabe (Wahrscheinlichkeiten)\n",
    "```\n",
    "\n",
    "### Warum 256x256 und 4 Conv-BlÃ¶cke?\n",
    "\n",
    "| Aspekt | 128x128 (3 BlÃ¶cke) | 256x256 (4 BlÃ¶cke) |\n",
    "|--------|-------------------|--------------------|\n",
    "| **BildqualitÃ¤t** | Verpixelt | Gut erkennbar âœ“ |\n",
    "| **Parameter** | ~3.3 Mio | ~13 Mio |\n",
    "| **Trainingszeit** | ~2 Min | ~5 Min |\n",
    "| **Genauigkeit** | ~96% | ~98% (erwartet) |\n",
    "\n",
    "Bei hÃ¶herer AuflÃ¶sung brauchen wir **mehr Conv-BlÃ¶cke**, um die rÃ¤umliche\n",
    "Dimension ausreichend zu reduzieren bevor wir zum Dense Layer kommen.\n",
    "\n",
    "### Die einzelnen Schichten erklÃ¤rt:\n",
    "\n",
    "| Schicht | Funktion | Vorlesungsbezug |\n",
    "|---------|----------|-----------------|\n",
    "| **Rescaling** | Normalisiert Pixel auf [0,1] | Vorverarbeitung |\n",
    "| **Conv2D** | Erkennt lokale Muster (Kanten, Texturen) | Faltungsschicht |\n",
    "| **ReLU** | Aktivierungsfunktion, fÃ¼hrt NichtlinearitÃ¤t ein | Detector Layer |\n",
    "| **MaxPooling2D** | Reduziert Dimension, behÃ¤lt wichtige Features | Pooling Layer |\n",
    "| **Flatten** | Wandelt 2D-Features in 1D-Vektor um | Ãœbergang zu MLP |\n",
    "| **Dense** | Vollverbundene Schicht, lernt Kombinationen | Hidden Layer |\n",
    "| **Softmax** | Erzeugt Wahrscheinlichkeiten fÃ¼r jede Klasse | Output Layer |\n",
    "\n",
    "### Was macht die Faltung (Convolution)?\n",
    "\n",
    "Die Faltung ist das HerzstÃ¼ck eines CNNs. Ein kleiner **Filter (Kernel)** von z.B. 3x3 Pixeln wandert Ã¼ber das Bild und berechnet an jeder Position eine gewichtete Summe. Verschiedene Filter erkennen verschiedene Muster:\n",
    "- Filter 1 erkennt vielleicht horizontale Kanten\n",
    "\n",
    "- Filter 2 erkennt vertikale Kanten- **BehÃ¤lt die wichtigsten Features** (die hÃ¶chsten Aktivierungen)\n",
    "\n",
    "- Filter 3 erkennt Ecken- **Macht das Modell robuster** gegen kleine Verschiebungen\n",
    "\n",
    "- ...- **Reduziert die Datenmenge** (2x2 â†’ 1 Wert = 75% Reduktion)\n",
    "\n",
    "MaxPooling nimmt aus einem Bereich (z.B. 2x2 Pixel) nur den **maximalen Wert**. Das:\n",
    "\n",
    "Das Modell **lernt automatisch**, welche Filter nÃ¼tzlich sind!\n",
    "\n",
    "### Was macht das Pooling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 5. DAS CNN-MODELL ERSTELLEN\n",
    "# ==============================================================================\n",
    "# Jetzt bauen wir unser Convolutional Neural Network!\n",
    "#\n",
    "# Wir verwenden die Sequential-API von Keras, die es erlaubt, Schichten\n",
    "# einfach hintereinander zu stapeln - wie Legosteine!\n",
    "#\n",
    "# ARCHITEKTUR-ÃœBERSICHT (256x256 mit 4 Conv-BlÃ¶cken):\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚  INPUT: 256x256x3 (HÃ¶he x Breite x RGB-KanÃ¤le)                          â”‚\n",
    "# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "# â”‚  1. Rescaling: Normalisierung der Pixelwerte auf [0, 1]                 â”‚\n",
    "# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "# â”‚  2. Conv2D(32) + ReLU + MaxPool  â†’  Feature Maps: 127x127x32            â”‚\n",
    "# â”‚  3. Conv2D(64) + ReLU + MaxPool  â†’  Feature Maps: 62x62x64              â”‚\n",
    "# â”‚  4. Conv2D(128) + ReLU + MaxPool â†’  Feature Maps: 30x30x128             â”‚\n",
    "# â”‚  5. Conv2D(256) + ReLU + MaxPool â†’  Feature Maps: 14x14x256  (NEU!)     â”‚\n",
    "# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "# â”‚  6. Flatten: 14*14*256 = 50.176 Neuronen                                â”‚\n",
    "# â”‚  7. Dense(256) + ReLU: Vollverbundene Schicht (mehr KapazitÃ¤t!)         â”‚\n",
    "# â”‚  8. Dropout(0.5): Regularisierung gegen Overfitting                     â”‚\n",
    "# â”‚  9. Dense(num_classes) + Softmax: Ausgabe-Wahrscheinlichkeiten          â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#\n",
    "# WARUM 256x256 UND 4 BLÃ–CKE STATT 128x128 UND 3 BLÃ–CKE?\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Bei 128x128 waren die Bilder verpixelt und feine Details (Zahlen, Symbole)\n",
    "# gingen verloren. Mit 256x256 bleiben diese Details erhalten.\n",
    "#\n",
    "# Der 4. Conv-Block ist nÃ¶tig, weil:\n",
    "# 1. Bei hÃ¶herer AuflÃ¶sung mÃ¼ssen wir die Feature Maps weiter reduzieren\n",
    "# 2. Tiefere Netze kÃ¶nnen komplexere Muster lernen\n",
    "# 3. Das Flatten am Ende sollte nicht zu viele Neuronen haben\n",
    "#\n",
    "# Vergleich:\n",
    "# | Konfiguration      | Parameter   | Flatten-Neuronen |\n",
    "# |--------------------|-------------|------------------|\n",
    "# | 128x128, 3 BlÃ¶cke  | ~3.3 Mio    | 25.088          |\n",
    "# | 256x256, 3 BlÃ¶cke  | ~15 Mio     | 115.200 âŒ      |\n",
    "# | 256x256, 4 BlÃ¶cke  | ~13 Mio     | 50.176 âœ“       |\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CNN-MODELL ERSTELLEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model = Sequential([\n",
    "    # =========================================================================\n",
    "    # NORMALISIERUNG: Pixelwerte von [0,255] auf [0,1] skalieren\n",
    "    # =========================================================================\n",
    "    layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    \n",
    "    # =========================================================================\n",
    "    # BLOCK 1: 32 Filter (Kanten, einfache Muster)\n",
    "    # Eingabe: 256x256x3 â†’ Ausgabe: 127x127x32\n",
    "    # =========================================================================\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # =========================================================================\n",
    "    # BLOCK 2: 64 Filter (Ecken, Kombinationen aus Kanten)\n",
    "    # Eingabe: 127x127x32 â†’ Ausgabe: 62x62x64\n",
    "    # =========================================================================\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # =========================================================================\n",
    "    # BLOCK 3: 128 Filter (Komplexere Formen, Teile von Symbolen)\n",
    "    # Eingabe: 62x62x64 â†’ Ausgabe: 30x30x128\n",
    "    # =========================================================================\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # =========================================================================\n",
    "    # BLOCK 4: 256 Filter (NEU! Ganze Symbole, Kartentypen)\n",
    "    # Eingabe: 30x30x128 â†’ Ausgabe: 14x14x256\n",
    "    #\n",
    "    # Dieser Block ist neu fÃ¼r 256x256 Bilder und ermÃ¶glicht:\n",
    "    # - Erkennung von ganzen Zahlen und Symbolen\n",
    "    # - Unterscheidung Ã¤hnlicher Karten (z.B. 8 vs 9)\n",
    "    # - Abstrakte ReprÃ¤sentation des Kartentyps\n",
    "    # =========================================================================\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # =========================================================================\n",
    "    # ÃœBERGANG: Flatten (3D â†’ 1D)\n",
    "    # 14 Ã— 14 Ã— 256 = 50.176 Neuronen\n",
    "    # =========================================================================\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # =========================================================================\n",
    "    # KLASSIFIKATOR: Dense Layer mit 256 Neuronen\n",
    "    # Mehr Neuronen wegen mehr Input-Features\n",
    "    # =========================================================================\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    \n",
    "    # =========================================================================\n",
    "    # DROPOUT: 50% der Neuronen zufÃ¤llig deaktivieren (Regularisierung)\n",
    "    # =========================================================================\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    # =========================================================================\n",
    "    # AUSGABE: Softmax fÃ¼r Wahrscheinlichkeiten pro Klasse\n",
    "    # =========================================================================\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "print(\"âœ… Modell erfolgreich erstellt!\")\n",
    "print(f\"   EingabegrÃ¶ÃŸe: {IMG_HEIGHT} x {IMG_WIDTH} x 3\")\n",
    "print(f\"   Anzahl Conv-BlÃ¶cke: 4\")\n",
    "print(f\"   Anzahl Klassen: {num_classes}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde8cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 5.1 MODELL-ZUSAMMENFASSUNG ANZEIGEN\n",
    "# ==============================================================================\n",
    "# model.summary() zeigt uns eine Ãœbersicht Ã¼ber unser Modell:\n",
    "# - Welche Schichten hat es?\n",
    "# - Wie viele Parameter (Gewichte) hat jede Schicht?\n",
    "# - Wie groÃŸ ist die Ausgabe jeder Schicht?\n",
    "#\n",
    "# Dies hilft uns zu verstehen, was im Modell passiert.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODELL-ZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Modell-Zusammenfassung ausgeben\n",
    "model.summary()\n",
    "\n",
    "# ErklÃ¤rung der Parameter\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ERKLÃ„RUNG DER PARAMETER\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Was bedeuten diese Zahlen?\n",
    "\n",
    "ğŸ“Š \"Output Shape\":\n",
    "   - Die Dimensionen der Ausgabe dieser Schicht\n",
    "   - (None, 63, 63, 32) bedeutet: Beliebige Batch-GrÃ¶ÃŸe, 63x63 Pixel, 32 Feature Maps\n",
    "\n",
    "ğŸ“Š \"Param #\":\n",
    "   - Anzahl der lernbaren Parameter (Gewichte + Bias)\n",
    "   - Bei Conv2D: (KernelgrÃ¶ÃŸe Ã— KernelgrÃ¶ÃŸe Ã— EingabekanÃ¤le Ã— Anzahl Filter) + Bias\n",
    "   - Beispiel erste Conv2D: (3 Ã— 3 Ã— 3 Ã— 32) + 32 = 896\n",
    "\n",
    "ğŸ“Š \"Total params\":\n",
    "   - Gesamtzahl aller Parameter im Modell\n",
    "   - Das sind die Werte, die das Modell wÃ¤hrend des Trainings lernt!\n",
    "\n",
    "ğŸ“Š \"Trainable params\":\n",
    "   - Parameter, die wÃ¤hrend des Trainings angepasst werden\n",
    "\n",
    "ğŸ“Š \"Non-trainable params\":\n",
    "   - Parameter, die nicht angepasst werden (z.B. bei Transfer Learning)\n",
    "\"\"\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdb620",
   "metadata": {},
   "source": [
    "## 6. Modell kompilieren\n",
    "\n",
    "Bevor wir das Modell trainieren kÃ¶nnen, mÃ¼ssen wir es **kompilieren**. Dabei legen wir fest:\n",
    "\n",
    "1. **Optimizer (Optimierer):**\n",
    "   - Der Algorithmus, der die Gewichte anpasst\n",
    "   - Wir verwenden **Adam** (Adaptive Moment Estimation)\n",
    "   - Adam ist robust und funktioniert fÃ¼r die meisten Probleme gut\n",
    "   - Er kombiniert die Vorteile von RMSprop und Momentum\n",
    "\n",
    "2. **Loss Function (Verlustfunktion):**\n",
    "   - Misst, wie weit die Vorhersage vom wahren Wert entfernt ist\n",
    "   - Bei Mehrklassen-Klassifikation: **Sparse Categorical Crossentropy**\n",
    "   - \"Sparse\" bedeutet: Labels sind Integers (0, 1, 2, ...), nicht One-Hot-Encoded\n",
    "\n",
    "3. **Metrics (Metriken):**\n",
    "   - Was wollen wir wÃ¤hrend des Trainings beobachten?\n",
    "   - **Accuracy**: Anteil der korrekt klassifizierten Bilder\n",
    "\n",
    "### Was ist Backpropagation?\n",
    "\n",
    "Keras erledigt das automatisch, aber hier die Grundidee:\n",
    "\n",
    "1. **Forward Pass:** Eingabe â†’ durch alle Schichten â†’ Vorhersage\n",
    "2. **Loss berechnen:** Wie falsch war die Vorhersage?\n",
    "3. **Backward Pass:** Fehler zurÃ¼ck durch alle Schichten propagieren\n",
    "4. **Gradienten berechnen:** Wie mÃ¼ssen wir die Gewichte Ã¤ndern, um den Fehler zu reduzieren?\n",
    "5. **Gewichte aktualisieren:** Der Optimizer passt die Gewichte an\n",
    "\n",
    "Dieser Prozess wiederholt sich fÃ¼r jeden Batch, fÃ¼r jede Epoche!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19284588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 6. MODELL KOMPILIEREN\n",
    "# ==============================================================================\n",
    "# Das Kompilieren konfiguriert den Trainingsprozess.\n",
    "# Wir legen fest:\n",
    "# - WIE das Modell lernt (Optimizer)\n",
    "# - WAS minimiert werden soll (Loss)\n",
    "# - WAS wir beobachten wollen (Metrics)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODELL KOMPILIEREN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- Optimizer: Adam ---\n",
    "# Adam (Adaptive Moment Estimation) ist einer der beliebtesten Optimizer.\n",
    "# Er kombiniert zwei Ideen:\n",
    "# 1. Momentum: Nutzt vergangene Gradienten, um Oszillationen zu reduzieren\n",
    "# 2. RMSprop: Passt die Lernrate fÃ¼r jeden Parameter individuell an\n",
    "#\n",
    "# learning_rate=0.001 ist der Standardwert\n",
    "# - Zu hoch: Training instabil, \"springt\" Ã¼ber das Optimum hinweg\n",
    "# - Zu niedrig: Training sehr langsam\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# --- Loss: Sparse Categorical Crossentropy ---\n",
    "# Diese Loss-Funktion ist fÃ¼r Mehrklassen-Klassifikation mit Integer-Labels.\n",
    "#\n",
    "# \"Sparse\" bedeutet: Unsere Labels sind Zahlen (0, 1, 2, ...)\n",
    "# Alternativ gÃ¤be es \"categorical_crossentropy\" fÃ¼r One-Hot-Labels\n",
    "# (z.B. [1,0,0], [0,1,0], [0,0,1])\n",
    "#\n",
    "# Crossentropy misst den Unterschied zwischen:\n",
    "# - Der vorhergesagten Wahrscheinlichkeitsverteilung\n",
    "# - Der wahren Verteilung (100% fÃ¼r die richtige Klasse, 0% fÃ¼r alle anderen)\n",
    "#\n",
    "# Je niedriger der Loss, desto besser die Vorhersage!\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "\n",
    "# --- Metrics: Accuracy ---\n",
    "# Accuracy = Anzahl korrekter Vorhersagen / Gesamtzahl Vorhersagen\n",
    "# Bei 100 Bildern und 85 richtigen Vorhersagen: Accuracy = 0.85 = 85%\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "print(\"âœ… Modell erfolgreich kompiliert!\")\n",
    "print(f\"   Optimizer: Adam (learning_rate=0.001)\")\n",
    "print(f\"   Loss: {loss}\")\n",
    "print(f\"   Metrics: {metrics}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf159154",
   "metadata": {},
   "source": [
    "## 7. Training des Modells\n",
    "\n",
    "Jetzt trainieren wir unser CNN! Der Trainingsprozess funktioniert so:\n",
    "\n",
    "### Der Trainingsablauf\n",
    "\n",
    "```\n",
    "FÃ¼r jede Epoche:\n",
    "    FÃ¼r jeden Batch:\n",
    "        1. Lade einen Batch von Bildern (z.B. 32 StÃ¼ck)\n",
    "        2. Forward Pass: Berechne Vorhersagen fÃ¼r alle Bilder\n",
    "        3. Berechne den Loss (Fehler)\n",
    "        4. Backward Pass: Berechne Gradienten (Backpropagation)\n",
    "        5. Update: Passe die Gewichte an (mit dem Optimizer)\n",
    "    \n",
    "    Nach allen Batches:\n",
    "        - Berechne Metriken auf Validierungsdaten\n",
    "        - Zeige Training/Validation Loss und Accuracy\n",
    "```\n",
    "\n",
    "### Was bedeuten die Ausgaben wÃ¤hrend des Trainings?\n",
    "\n",
    "- **loss:** Der Trainingsfehler (soll sinken)\n",
    "- **accuracy:** Die Trainingsgenauigkeit (soll steigen)\n",
    "- **val_loss:** Der Validierungsfehler (soll auch sinken)\n",
    "- **val_accuracy:** Die Validierungsgenauigkeit (zeigt, wie gut das Modell generalisiert)\n",
    "\n",
    "### Wie erkennt man Overfitting?\n",
    "\n",
    "Typische Anzeichen:\n",
    "- Training-Accuracy ist hoch, aber Validation-Accuracy bleibt niedrig\n",
    "- Training-Loss sinkt weiter, aber Validation-Loss steigt\n",
    "\n",
    "Wenn das passiert, lernt das Modell die Trainingsdaten \"auswendig\" statt zu generalisieren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 7. TRAINING DES MODELLS\n",
    "# ==============================================================================\n",
    "# Jetzt kommt der spannende Teil: Wir trainieren unser CNN!\n",
    "#\n",
    "# model.fit() ist die zentrale Methode zum Training in Keras.\n",
    "# Sie fÃ¼hrt den gesamten Trainingsprozess durch:\n",
    "# - Forward Pass\n",
    "# - Loss-Berechnung  \n",
    "# - Backpropagation\n",
    "# - Gewichtsanpassung\n",
    "#\n",
    "# Alles automatisch! Das ist die StÃ¤rke von Keras.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING STARTEN\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“Š Anzahl Epochen: {EPOCHS}\")\n",
    "print(f\"ğŸ“¦ Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"ğŸ¯ Anzahl Klassen: {num_classes}\")\n",
    "print()\n",
    "print(\"ğŸ’¡ Tipp: Beobachte val_accuracy - das zeigt, wie gut das Modell generalisiert!\")\n",
    "print()\n",
    "print(\"Training lÃ¤uft... (Dies kann einige Minuten dauern)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# --- Training durchfÃ¼hren ---\n",
    "# Die fit()-Methode gibt ein \"History\"-Objekt zurÃ¼ck,\n",
    "# das den Verlauf von Loss und Accuracy enthÃ¤lt.\n",
    "# Das speichern wir, um spÃ¤ter Plots zu erstellen.\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,              # Trainingsdaten\n",
    "    epochs=EPOCHS,              # Anzahl der DurchlÃ¤ufe durch alle Daten\n",
    "    validation_data=val_dataset, # Validierungsdaten zur Ãœberwachung\n",
    "    verbose=1                   # 1 = Fortschritt anzeigen, 0 = still\n",
    ")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"âœ… Training abgeschlossen!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 7.1 TRAININGSVERLAUF VISUALISIEREN\n",
    "# ==============================================================================\n",
    "# Es ist sehr wichtig, den Trainingsverlauf zu visualisieren!\n",
    "# So kÃ¶nnen wir erkennen:\n",
    "# - Lernt das Modell Ã¼berhaupt? (Loss sinkt, Accuracy steigt)\n",
    "# - Gibt es Overfitting? (Training-Accuracy >> Validation-Accuracy)\n",
    "# - Wie viele Epochen sind optimal?\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAININGSVERLAUF VISUALISIEREN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Daten aus dem History-Objekt extrahieren\n",
    "train_loss = history.history['loss']           # Trainingsfehler pro Epoche\n",
    "val_loss = history.history['val_loss']         # Validierungsfehler pro Epoche\n",
    "train_acc = history.history['accuracy']        # Trainingsgenauigkeit pro Epoche\n",
    "val_acc = history.history['val_accuracy']      # Validierungsgenauigkeit pro Epoche\n",
    "epochen = range(1, len(train_loss) + 1)        # Epochen-Nummern (1, 2, 3, ...)\n",
    "\n",
    "# Zwei Plots nebeneinander: Loss und Accuracy\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# --- Plot 1: Loss (Verlust) ---\n",
    "ax1.plot(epochen, train_loss, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "ax1.plot(epochen, val_loss, 'r-o', label='Validation Loss', linewidth=2, markersize=6)\n",
    "ax1.set_title('Verlustfunktion (Loss) Ã¼ber die Epochen', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Epoche', fontsize=10)\n",
    "ax1.set_ylabel('Loss', fontsize=10)\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 2: Accuracy (Genauigkeit) ---\n",
    "ax2.plot(epochen, train_acc, 'b-o', label='Training Accuracy', linewidth=2, markersize=6)\n",
    "ax2.plot(epochen, val_acc, 'r-o', label='Validation Accuracy', linewidth=2, markersize=6)\n",
    "ax2.set_title('Genauigkeit (Accuracy) Ã¼ber die Epochen', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Epoche', fontsize=10)\n",
    "ax2.set_ylabel('Accuracy', fontsize=10)\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 1])  # Accuracy ist immer zwischen 0 und 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Interpretation ---\n",
    "print(\"\\nğŸ“Š INTERPRETATION DER KURVEN:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Finale Training-Accuracy:   {train_acc[-1]*100:.2f}%\")\n",
    "print(f\"Finale Validation-Accuracy: {val_acc[-1]*100:.2f}%\")\n",
    "print(f\"Finale Training-Loss:       {train_loss[-1]:.4f}\")\n",
    "print(f\"Finale Validation-Loss:     {val_loss[-1]:.4f}\")\n",
    "print()\n",
    "\n",
    "# Overfitting-Check\n",
    "diff = train_acc[-1] - val_acc[-1]\n",
    "if diff > 0.1:\n",
    "    print(\"âš ï¸ MÃ–GLICHES OVERFITTING ERKANNT!\")\n",
    "    print(f\"   Die Training-Accuracy ist {diff*100:.1f}% hÃ¶her als die Validation-Accuracy.\")\n",
    "    print(\"   Das Modell kÃ¶nnte die Trainingsdaten 'auswendig lernen'.\")\n",
    "    print(\"   MÃ¶gliche LÃ¶sungen: Mehr Dropout, mehr Daten, weniger Epochen\")\n",
    "else:\n",
    "    print(\"âœ… Kein starkes Overfitting erkennbar.\")\n",
    "    print(\"   Training- und Validation-Kurven verlaufen Ã¤hnlich.\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee99f9c",
   "metadata": {},
   "source": [
    "## 8. Evaluation: Wie gut ist unser Modell?\n",
    "\n",
    "Nach dem Training wollen wir wissen, wie gut unser Modell wirklich ist. DafÃ¼r evaluieren wir es auf den Validierungsdaten.\n",
    "\n",
    "### Wichtige Metriken\n",
    "\n",
    "1. **Accuracy (Genauigkeit):**\n",
    "   - Anteil der korrekt klassifizierten Bilder\n",
    "   - Bei 53 Klassen ist selbst 50% schon deutlich besser als Zufall (1/53 â‰ˆ 1.9%)!\n",
    "\n",
    "2. **Loss:**\n",
    "   - Der Wert der Verlustfunktion\n",
    "   - Je niedriger, desto besser\n",
    "\n",
    "3. **Confusion Matrix:**\n",
    "   - Zeigt, welche Klassen verwechselt werden\n",
    "   - Auf der Diagonale stehen die korrekten Vorhersagen\n",
    "   - AuÃŸerhalb der Diagonale stehen die Verwechslungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26af4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 8. MODELL EVALUIEREN\n",
    "# ==============================================================================\n",
    "# Wir evaluieren das Modell auf den Validierungsdaten.\n",
    "# model.evaluate() berechnet Loss und Accuracy auf einem Datensatz.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODELL EVALUIEREN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluation auf Validierungsdaten\n",
    "print(\"ğŸ“Š Evaluiere Modell auf Validierungsdaten...\")\n",
    "val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "\n",
    "print()\n",
    "print(\"ğŸ“ˆ ERGEBNISSE:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"   Validation Loss:     {val_loss:.4f}\")\n",
    "print(f\"   Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Kontext geben: Wie gut ist das im Vergleich zu Zufall?\n",
    "zufall_accuracy = 1 / num_classes * 100\n",
    "print(f\"ğŸ’¡ Zum Vergleich: ZufÃ¤lliges Raten wÃ¼rde ~{zufall_accuracy:.1f}% erreichen\")\n",
    "print(f\"   Unser Modell ist {val_accuracy*100/zufall_accuracy:.1f}x besser als Zufall!\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 8.1 VORHERSAGEN SAMMELN FÃœR CONFUSION MATRIX\n",
    "# ==============================================================================\n",
    "# Um eine Confusion Matrix zu erstellen, brauchen wir:\n",
    "# - Alle wahren Labels\n",
    "# - Alle vorhergesagten Labels\n",
    "#\n",
    "# Wir gehen durch alle Validierungsdaten und sammeln diese.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VORHERSAGEN SAMMELN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Listen fÃ¼r wahre und vorhergesagte Labels\n",
    "y_true = []  # Die wahren Labels\n",
    "y_pred = []  # Die vorhergesagten Labels\n",
    "\n",
    "print(\"ğŸ“Š Sammle Vorhersagen fÃ¼r alle Validierungsbilder...\")\n",
    "\n",
    "# Durch alle Batches im Validierungsdatensatz gehen\n",
    "for images, labels in val_dataset:\n",
    "    # Vorhersagen fÃ¼r diesen Batch machen\n",
    "    # model.predict() gibt Wahrscheinlichkeiten fÃ¼r jede Klasse zurÃ¼ck\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    \n",
    "    # Die vorhergesagte Klasse ist die mit der hÃ¶chsten Wahrscheinlichkeit\n",
    "    # np.argmax() findet den Index des hÃ¶chsten Wertes\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Labels zu unseren Listen hinzufÃ¼gen\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(predicted_labels)\n",
    "\n",
    "# In NumPy-Arrays umwandeln\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "print(f\"âœ… {len(y_true)} Vorhersagen gesammelt!\")\n",
    "print(f\"   Korrekte Vorhersagen: {np.sum(y_true == y_pred)}\")\n",
    "print(f\"   Falsche Vorhersagen: {np.sum(y_true != y_pred)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1aec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 8.2 CONFUSION MATRIX ERSTELLEN\n",
    "# ==============================================================================\n",
    "# Die Confusion Matrix zeigt, wie oft jede Klasse mit jeder anderen\n",
    "# verwechselt wurde.\n",
    "#\n",
    "# Wie liest man die Matrix?\n",
    "# - Zeilen = Wahre Klasse\n",
    "# - Spalten = Vorhergesagte Klasse\n",
    "# - Diagonale = Korrekte Vorhersagen\n",
    "# - Andere Felder = Verwechslungen\n",
    "#\n",
    "# Beispiel: Wenn Feld (5, 8) den Wert 3 hat, bedeutet das:\n",
    "# \"Klasse 5 wurde 3 mal fÃ¤lschlich als Klasse 8 vorhergesagt\"\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFUSION MATRIX ERSTELLEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Confusion Matrix berechnen\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Bei vielen Klassen ist die volle Matrix schwer lesbar\n",
    "# Wir zeigen eine vereinfachte Version\n",
    "\n",
    "if num_classes <= 20:\n",
    "    # Bei wenigen Klassen: Volle Matrix anzeigen\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Vorhergesagte Klasse', fontsize=12)\n",
    "    plt.ylabel('Wahre Klasse', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    # Bei vielen Klassen: Nur die hÃ¤ufigsten Verwechslungen zeigen\n",
    "    print(f\"\\nâš ï¸ Bei {num_classes} Klassen ist die volle Matrix schwer lesbar.\")\n",
    "    print(\"   Zeige stattdessen die hÃ¤ufigsten Verwechslungen:\\n\")\n",
    "    \n",
    "    # Finde die hÃ¤ufigsten Fehler (auÃŸerhalb der Diagonale)\n",
    "    fehler = []\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                fehler.append({\n",
    "                    'wahre_klasse': class_names[i],\n",
    "                    'vorhergesagt': class_names[j],\n",
    "                    'anzahl': cm[i, j]\n",
    "                })\n",
    "    \n",
    "    # Nach Anzahl sortieren\n",
    "    fehler.sort(key=lambda x: x['anzahl'], reverse=True)\n",
    "    \n",
    "    # Top 10 Fehler anzeigen\n",
    "    print(\"ğŸ“Š Top 10 hÃ¤ufigste Verwechslungen:\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, f in enumerate(fehler[:10], 1):\n",
    "        print(f\"   {i:2}. '{f['wahre_klasse']}' wurde {f['anzahl']}x als '{f['vorhergesagt']}' erkannt\")\n",
    "\n",
    "# Zusammenfassung der Confusion Matrix\n",
    "print(\"\\nğŸ“Š ZUSAMMENFASSUNG:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"   Gesamtzahl Bilder: {len(y_true)}\")\n",
    "print(f\"   Korrekt (Diagonale): {np.trace(cm)}\")\n",
    "print(f\"   Falsch (Rest): {np.sum(cm) - np.trace(cm)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff05164",
   "metadata": {},
   "source": [
    "## 9. Beispielvorhersagen anzeigen\n",
    "\n",
    "Zum Abschluss schauen wir uns einige konkrete Vorhersagen an. Das hilft uns zu verstehen:\n",
    "- Bei welchen Karten funktioniert das Modell gut?\n",
    "- Bei welchen Karten macht es Fehler?\n",
    "- Sind die Fehler nachvollziehbar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd59536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 9. BEISPIELVORHERSAGEN ANZEIGEN\n",
    "# ==============================================================================\n",
    "# Wir zeigen einige zufÃ¤llige Bilder aus dem Validierungsdatensatz zusammen\n",
    "# mit der wahren Klasse und der Vorhersage des Modells.\n",
    "#\n",
    "# GrÃ¼n = Korrekte Vorhersage\n",
    "# Rot = Falsche Vorhersage\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BEISPIELVORHERSAGEN ANZEIGEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Einige Bilder aus dem Validierungsdatensatz sammeln\n",
    "beispiel_bilder = []\n",
    "beispiel_labels = []\n",
    "\n",
    "for images, labels in val_dataset.take(1):  # Nur einen Batch\n",
    "    beispiel_bilder = images.numpy()\n",
    "    beispiel_labels = labels.numpy()\n",
    "    break\n",
    "\n",
    "# 9 zufÃ¤llige Beispiele auswÃ¤hlen\n",
    "anzahl_beispiele = 9\n",
    "if len(beispiel_bilder) >= anzahl_beispiele:\n",
    "    indizes = random.sample(range(len(beispiel_bilder)), anzahl_beispiele)\n",
    "else:\n",
    "    indizes = list(range(len(beispiel_bilder)))\n",
    "\n",
    "# Vorhersagen fÃ¼r diese Bilder\n",
    "ausgewaehlte_bilder = beispiel_bilder[indizes]\n",
    "ausgewaehlte_labels = beispiel_labels[indizes]\n",
    "vorhersagen = model.predict(ausgewaehlte_bilder, verbose=0)\n",
    "vorhergesagte_klassen = np.argmax(vorhersagen, axis=1)\n",
    "konfidenz = np.max(vorhersagen, axis=1)  # HÃ¶chste Wahrscheinlichkeit\n",
    "\n",
    "# Plot erstellen\n",
    "fig, axes = plt.subplots(3, 3, figsize=(14, 14))\n",
    "fig.suptitle('Beispielvorhersagen des CNN-Modells', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    if idx < len(indizes):\n",
    "        # Bild anzeigen (Normalisierung rÃ¼ckgÃ¤ngig machen fÃ¼r Anzeige)\n",
    "        bild = ausgewaehlte_bilder[idx]\n",
    "        ax.imshow(bild.astype('uint8'))\n",
    "        \n",
    "        # Wahre und vorhergesagte Klasse\n",
    "        wahre_klasse = class_names[ausgewaehlte_labels[idx]]\n",
    "        vorhergesagt = class_names[vorhergesagte_klassen[idx]]\n",
    "        konf = konfidenz[idx] * 100\n",
    "        \n",
    "        # Korrekt oder falsch?\n",
    "        ist_korrekt = wahre_klasse == vorhergesagt\n",
    "        farbe = 'green' if ist_korrekt else 'red'\n",
    "        symbol = 'âœ“' if ist_korrekt else 'âœ—'\n",
    "        \n",
    "        # Titel mit Formatierung\n",
    "        titel = f\"{symbol} Wahr: {wahre_klasse}\\nVorhersage: {vorhergesagt}\\n({konf:.1f}% sicher)\"\n",
    "        ax.set_title(titel, fontsize=9, color=farbe, fontweight='bold')\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Zusammenfassung\n",
    "korrekt = sum(1 for i in range(len(indizes)) \n",
    "              if class_names[ausgewaehlte_labels[i]] == class_names[vorhergesagte_klassen[i]])\n",
    "print(f\"\\nğŸ“Š Von {len(indizes)} gezeigten Beispielen: {korrekt} korrekt, {len(indizes)-korrekt} falsch\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 9.1 FEHLGESCHLAGENE VORHERSAGEN ANALYSIEREN\n",
    "# ==============================================================================\n",
    "# Es ist besonders lehrreich, sich die Fehler anzuschauen.\n",
    "# So verstehen wir, wo das Modell Schwierigkeiten hat.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYSE DER FEHLGESCHLAGENEN VORHERSAGEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Finde Indizes, wo Vorhersage != wahres Label\n",
    "fehler_indizes = np.where(y_pred != y_true)[0]\n",
    "\n",
    "print(f\"ğŸ“Š Gesamtzahl der Fehler: {len(fehler_indizes)}\")\n",
    "print()\n",
    "\n",
    "if len(fehler_indizes) > 0:\n",
    "    # Einige Fehlerbeispiele sammeln\n",
    "    fehler_beispiele = []\n",
    "    \n",
    "    for images, labels in val_dataset:\n",
    "        for i, (img, label) in enumerate(zip(images, labels)):\n",
    "            # Vorhersage\n",
    "            pred = model.predict(np.expand_dims(img, 0), verbose=0)\n",
    "            pred_label = np.argmax(pred)\n",
    "            \n",
    "            if pred_label != label.numpy() and len(fehler_beispiele) < 6:\n",
    "                fehler_beispiele.append({\n",
    "                    'bild': img.numpy(),\n",
    "                    'wahr': class_names[label.numpy()],\n",
    "                    'vorhergesagt': class_names[pred_label],\n",
    "                    'konfidenz': np.max(pred) * 100\n",
    "                })\n",
    "        \n",
    "        if len(fehler_beispiele) >= 6:\n",
    "            break\n",
    "    \n",
    "    # Fehler visualisieren\n",
    "    if fehler_beispiele:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(14, 10))\n",
    "        fig.suptitle('Beispiele fÃ¼r FALSCHE Vorhersagen (zum Lernen!)', \n",
    "                     fontsize=14, fontweight='bold', color='red')\n",
    "        \n",
    "        for idx, ax in enumerate(axes.flat):\n",
    "            if idx < len(fehler_beispiele):\n",
    "                f = fehler_beispiele[idx]\n",
    "                ax.imshow(f['bild'].astype('uint8'))\n",
    "                titel = f\"âœ— Wahr: {f['wahr']}\\nVorhersage: {f['vorhergesagt']}\\n({f['konfidenz']:.1f}% sicher)\"\n",
    "                ax.set_title(titel, fontsize=9, color='red')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nğŸ’¡ ANALYSE: Warum macht das Modell diese Fehler?\")\n",
    "        print(\"-\" * 60)\n",
    "        print(\"   MÃ¶gliche GrÃ¼nde:\")\n",
    "        print(\"   - Ã„hnliche visuelle Merkmale bei verschiedenen Karten\")\n",
    "        print(\"   - Unterschiedliche BildqualitÃ¤t oder Beleuchtung\")\n",
    "        print(\"   - Zu wenige Trainingsbeispiele fÃ¼r bestimmte Klassen\")\n",
    "        print(\"   - Das Modell braucht mehr Epochen zum Lernen\")\n",
    "else:\n",
    "    print(\"ğŸ‰ Wow! Das Modell hat keine Fehler auf den Validierungsdaten gemacht!\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb72ab",
   "metadata": {},
   "source": [
    "## 10. Zusammenfassung und nÃ¤chste Schritte\n",
    "\n",
    "### Was haben wir gelernt?\n",
    "\n",
    "In diesem Notebook haben wir:\n",
    "\n",
    "1. **Ein CNN von Grund auf gebaut** mit:\n",
    "   - Convolution Layers (Faltungsschichten) zur Merkmalserkennung\n",
    "   - ReLU als Aktivierungsfunktion\n",
    "   - MaxPooling zur Dimensionsreduktion\n",
    "   - Dense Layers (vollverbundene Schichten) zur Klassifikation\n",
    "   - Softmax fÃ¼r Wahrscheinlichkeiten\n",
    "\n",
    "2. **Den Trainingsprozess verstanden:**\n",
    "   - Forward Pass: Eingabe â†’ Vorhersage\n",
    "   - Loss-Berechnung: Wie falsch war die Vorhersage?\n",
    "   - Backpropagation: Gradienten berechnen\n",
    "   - Gewichtsanpassung: Modell verbessern\n",
    "\n",
    "3. **Das Modell evaluiert:**\n",
    "   - Accuracy als Hauptmetrik\n",
    "   - Confusion Matrix zur Fehleranalyse\n",
    "   - Visualisierung von Beispielvorhersagen\n",
    "\n",
    "### Wie passt das zur Vorlesung?\n",
    "\n",
    "| Vorlesungskonzept | Umsetzung im Code |\n",
    "|-------------------|-------------------|\n",
    "| Eingabeschicht | `input_shape=(128, 128, 3)` |\n",
    "| Faltungsschicht (Convolution) | `Conv2D(32, (3,3), activation='relu')` |\n",
    "| Detector Layer (ReLU) | `activation='relu'` |\n",
    "| Pooling Layer | `MaxPooling2D((2, 2))` |\n",
    "| Flatten | `Flatten()` |\n",
    "| Hidden Layer (MLP) | `Dense(128, activation='relu')` |\n",
    "| Output Layer | `Dense(num_classes, activation='softmax')` |\n",
    "| Verlustfunktion | `sparse_categorical_crossentropy` |\n",
    "| Optimierung | Adam (Gradientenabstieg mit Momentum) |\n",
    "| Backpropagation | Automatisch durch `model.fit()` |\n",
    "\n",
    "### MÃ¶gliche Verbesserungen\n",
    "\n",
    "1. **Data Augmentation:** Bilder zufÃ¤llig drehen, spiegeln, zoomen fÃ¼r mehr Trainingsdaten\n",
    "2. **Transfer Learning:** Ein vortrainiertes Modell (z.B. VGG16, ResNet) als Basis verwenden\n",
    "3. **Mehr Epochen:** LÃ¤nger trainieren (mit Early Stopping gegen Overfitting)\n",
    "4. **Hyperparameter-Tuning:** Verschiedene Lernraten, Filter-Anzahlen, etc. ausprobieren\n",
    "5. **Batch Normalization:** Stabilisiert das Training bei tiefen Netzen\n",
    "\n",
    "### Weitere Ressourcen\n",
    "\n",
    "- [TensorFlow/Keras Dokumentation](https://www.tensorflow.org/guide/keras)\n",
    "- [CS231n: CNN for Visual Recognition (Stanford)](http://cs231n.stanford.edu/)\n",
    "- [Deep Learning Book (Goodfellow et al.)](https://www.deeplearningbook.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 10. MODELL SPEICHERN (OPTIONAL)\n",
    "# ==============================================================================\n",
    "# Wenn du zufrieden mit deinem Modell bist, kannst du es speichern.\n",
    "# So musst du nicht jedes Mal neu trainieren!\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODELL SPEICHERN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Modell speichern\n",
    "modell_pfad = \"spielkarten_cnn_modell.keras\"\n",
    "model.save(modell_pfad)\n",
    "\n",
    "print(f\"âœ… Modell gespeichert unter: {modell_pfad}\")\n",
    "print()\n",
    "print(\"ğŸ’¡ Um das Modell spÃ¤ter zu laden:\")\n",
    "print(f'   model = keras.models.load_model(\"{modell_pfad}\")')\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ==============================================================================\n",
    "# ABSCHLUSS\n",
    "# ==============================================================================\n",
    "print()\n",
    "print(\"ğŸ‰\" + \"=\" * 58 + \"ğŸ‰\")\n",
    "print(\"   HERZLICHEN GLÃœCKWUNSCH!\")\n",
    "print(\"   Du hast dein erstes CNN erfolgreich trainiert!\")\n",
    "print(\"ğŸ‰\" + \"=\" * 58 + \"ğŸ‰\")\n",
    "print()\n",
    "print(\"Was du gelernt hast:\")\n",
    "print(\"   âœ… Was ein Neuronales Netz ist\")\n",
    "print(\"   âœ… Was ein CNN ist und warum es fÃ¼r Bilder geeignet ist\")\n",
    "print(\"   âœ… Wie Convolution, Pooling und Dense Layers funktionieren\")\n",
    "print(\"   âœ… Wie man ein Modell trainiert und evaluiert\")\n",
    "print(\"   âœ… Wie man Ergebnisse interpretiert\")\n",
    "print()\n",
    "print(\"Viel Erfolg bei deinen weiteren Deep-Learning-Projekten! ğŸš€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7970cf",
   "metadata": {},
   "source": [
    "## 11. Eigene Bilder testen ğŸ“¸\n",
    "\n",
    "Jetzt wird es spannend! Du kannst dein trainiertes Modell mit **eigenen Fotos** testen.\n",
    "\n",
    "### So funktioniert's:\n",
    "\n",
    "1. **Mache ein Foto** von einer Spielkarte mit deinem Handy oder Kamera\n",
    "2. **Kopiere das Bild** in den Ordner `./data/input/`\n",
    "3. **FÃ¼hre die nÃ¤chste Zelle aus** - das Modell wird alle Bilder im Ordner klassifizieren!\n",
    "\n",
    "### Tipps fÃ¼r gute Ergebnisse:\n",
    "\n",
    "| Tipp | Beschreibung |\n",
    "|------|--------------|\n",
    "| ğŸ“· **Perspektive** | Fotografiere die Karte mÃ¶glichst von oben |\n",
    "| ğŸ’¡ **Beleuchtung** | Gute, gleichmÃ¤ÃŸige Beleuchtung ohne starke Schatten |\n",
    "| ğŸ¯ **Bildausschnitt** | Die Karte sollte den GroÃŸteil des Bildes einnehmen |\n",
    "| ğŸ–¼ï¸ **Format** | UnterstÃ¼tzt: `.jpg`, `.jpeg`, `.png` |\n",
    "\n",
    "### Hinweis:\n",
    "Das Modell wurde mit Bildern trainiert, die eine bestimmte Perspektive haben. Bei sehr anderen Blickwinkeln oder Beleuchtungen kann die Genauigkeit sinken - das ist normal und zeigt die Grenzen des Trainings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 11. EIGENE BILDER TESTEN\n",
    "# ==============================================================================\n",
    "# Mit dieser Funktion kannst du eigene Fotos von Spielkarten testen!\n",
    "# Lege deine Bilder einfach in den Ordner ./data/input/ und fÃ¼hre diese Zelle aus.\n",
    "#\n",
    "# ANLEITUNG:\n",
    "# 1. Mache ein Foto von einer Spielkarte\n",
    "# 2. Kopiere das Bild nach ./data/input/\n",
    "# 3. FÃ¼hre diese Zelle aus\n",
    "# 4. Das Modell zeigt dir seine Vorhersage!\n",
    "# ==============================================================================\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# --- Input-Ordner definieren und erstellen ---\n",
    "INPUT_DIR = os.path.join(DATA_DIR, \"input\")\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "def teste_eigene_bilder():\n",
    "    \"\"\"\n",
    "    LÃ¤dt alle Bilder aus ./data/input/ und klassifiziert sie mit dem trainierten Modell.\n",
    "    \n",
    "    Diese Funktion:\n",
    "    1. Sucht nach Bildern im Input-Ordner\n",
    "    2. LÃ¤dt und skaliert jedes Bild auf 128x128 Pixel\n",
    "    3. LÃ¤sst das trainierte CNN eine Vorhersage machen\n",
    "    4. Zeigt das Bild mit der Vorhersage und Konfidenz an\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EIGENE BILDER TESTEN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“ Input-Ordner: {os.path.abspath(INPUT_DIR)}\")\n",
    "    print()\n",
    "    \n",
    "    # --- Alle Bilddateien im Input-Ordner finden ---\n",
    "    erlaubte_endungen = ('.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG')\n",
    "    \n",
    "    if not os.path.exists(INPUT_DIR):\n",
    "        os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    bild_dateien = [f for f in os.listdir(INPUT_DIR) if f.endswith(erlaubte_endungen)]\n",
    "    \n",
    "    if not bild_dateien:\n",
    "        print(\"âš ï¸  Keine Bilder gefunden!\")\n",
    "        print()\n",
    "        print(\"ğŸ“‹ So testest du eigene Bilder:\")\n",
    "        print(f\"   1. Ã–ffne den Ordner: {os.path.abspath(INPUT_DIR)}\")\n",
    "        print(\"   2. Kopiere deine Spielkarten-Fotos hinein\")\n",
    "        print(\"   3. FÃ¼hre diese Zelle erneut aus\")\n",
    "        print()\n",
    "        print(\"ğŸ’¡ UnterstÃ¼tzte Formate: .jpg, .jpeg, .png\")\n",
    "        print(\"=\" * 60)\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“¸ {len(bild_dateien)} Bild(er) gefunden!\")\n",
    "    print()\n",
    "    \n",
    "    # --- Anzahl der Spalten fÃ¼r die Anzeige berechnen ---\n",
    "    anzahl_bilder = len(bild_dateien)\n",
    "    spalten = min(3, anzahl_bilder)\n",
    "    zeilen = (anzahl_bilder + spalten - 1) // spalten\n",
    "    \n",
    "    fig, axes = plt.subplots(zeilen, spalten, figsize=(5 * spalten, 6 * zeilen))\n",
    "    \n",
    "    # Axes-Array normalisieren (fÃ¼r konsistente Indexierung)\n",
    "    if anzahl_bilder == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # --- Jedes Bild laden, vorverarbeiten und klassifizieren ---\n",
    "    for idx, dateiname in enumerate(bild_dateien):\n",
    "        bild_pfad = os.path.join(INPUT_DIR, dateiname)\n",
    "        \n",
    "        try:\n",
    "            # Bild laden und auf richtige GrÃ¶ÃŸe bringen\n",
    "            bild = Image.open(bild_pfad)\n",
    "            bild = bild.convert('RGB')  # Falls PNG mit Alpha-Kanal\n",
    "            bild_resized = bild.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "            \n",
    "            # Zu NumPy-Array konvertieren und Batch-Dimension hinzufÃ¼gen\n",
    "            bild_array = np.array(bild_resized)\n",
    "            bild_array = np.expand_dims(bild_array, axis=0)  # Shape: (1, 128, 128, 3)\n",
    "            \n",
    "            # Vorhersage machen\n",
    "            vorhersage = model.predict(bild_array, verbose=0)\n",
    "            vorhergesagte_klasse_idx = np.argmax(vorhersage[0])\n",
    "            vorhergesagte_klasse = class_names[vorhergesagte_klasse_idx]\n",
    "            konfidenz = vorhersage[0][vorhergesagte_klasse_idx] * 100\n",
    "            \n",
    "            # Klassenname in lesbaren Namen umwandeln\n",
    "            lesbarer_name = klasse_zu_name(vorhergesagte_klasse)\n",
    "            \n",
    "            # Bild anzeigen (OriginalgrÃ¶ÃŸe)\n",
    "            ax = axes[idx]\n",
    "            ax.imshow(bild)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Farbe basierend auf Konfidenz\n",
    "            if konfidenz > 70:\n",
    "                farbe = 'green'\n",
    "                symbol = 'âœ…'\n",
    "            elif konfidenz > 40:\n",
    "                farbe = 'orange'\n",
    "                symbol = 'âš ï¸'\n",
    "            else:\n",
    "                farbe = 'red'\n",
    "                symbol = 'â“'\n",
    "            \n",
    "            # Titel mit Vorhersage\n",
    "            ax.set_title(\n",
    "                f\"ğŸ“„ {dateiname}\\n\\n\"\n",
    "                f\"{symbol} {lesbarer_name}\\n\"\n",
    "                f\"({vorhergesagte_klasse})\\n\\n\"\n",
    "                f\"Konfidenz: {konfidenz:.1f}%\", \n",
    "                fontsize=11, color=farbe, fontweight='bold'\n",
    "            )\n",
    "            \n",
    "            # Details in Konsole ausgeben\n",
    "            print(f\"ğŸ“· {dateiname}\")\n",
    "            print(f\"   â†’ Vorhersage: {lesbarer_name} ({vorhergesagte_klasse})\")\n",
    "            print(f\"   â†’ Konfidenz: {konfidenz:.1f}%\")\n",
    "            \n",
    "            # Top 3 Vorhersagen anzeigen\n",
    "            top3_idx = np.argsort(vorhersage[0])[-3:][::-1]\n",
    "            print(\"   â†’ Top 3 Kandidaten:\")\n",
    "            for i, klassen_idx in enumerate(top3_idx):\n",
    "                k = class_names[klassen_idx]\n",
    "                p = vorhersage[0][klassen_idx] * 100\n",
    "                print(f\"      {i+1}. {klasse_zu_name(k)} ({k}): {p:.1f}%\")\n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Fehler beim Laden von {dateiname}: {e}\")\n",
    "            axes[idx].text(0.5, 0.5, f\"Fehler:\\n{e}\", ha='center', va='center')\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    # Leere Subplots ausblenden\n",
    "    for idx in range(len(bild_dateien), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ’¡ INTERPRETATION DER ERGEBNISSE:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"   âœ… GrÃ¼n (>70%):   Hohe Konfidenz - wahrscheinlich korrekt\")\n",
    "    print(\"   âš ï¸  Orange (40-70%): Mittlere Konfidenz - unsicher\")\n",
    "    print(\"   â“ Rot (<40%):    Niedrige Konfidenz - wahrscheinlich falsch\")\n",
    "    print()\n",
    "    print(\"   Bei niedriger Konfidenz: Versuche ein besseres Foto!\")\n",
    "    print(\"   - Bessere Beleuchtung\")\n",
    "    print(\"   - Karte gerade/von oben fotografieren\")\n",
    "    print(\"   - Karte sollte GroÃŸteil des Bildes einnehmen\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# --- Funktion ausfÃ¼hren ---\n",
    "teste_eigene_bilder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computational-intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
